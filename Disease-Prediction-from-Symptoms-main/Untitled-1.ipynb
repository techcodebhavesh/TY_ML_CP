{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\bhave\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3361\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3362\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\bhave\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\_libs\\index.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\bhave\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\_libs\\index.pyx:108\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'x'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load the Iris dataset\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# iris = load_iris()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# # For simplicity, let's focus on 'sepal length (cm)' feature\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# data = df['sepal length (cm)'].values\u001b[39;00m\n\u001b[0;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md:/downloadsD/Clustering_gmm.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Define the negative log-likelihood function\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnegative_log_likelihood\u001b[39m(params, data):\n",
      "File \u001b[1;32mc:\\Users\\bhave\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:3458\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3458\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3460\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\bhave\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3363\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3362\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3363\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_scalar(key) \u001b[38;5;129;01mand\u001b[39;00m isna(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhasnans:\n\u001b[0;32m   3366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'x'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "# iris = load_iris()\n",
    "# df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\n",
    "\n",
    "# # For simplicity, let's focus on 'sepal length (cm)' feature\n",
    "# data = df['sepal length (cm)'].values\n",
    "data = pd.read_csv('d:/downloadsD/Clustering_gmm.csv')\n",
    "data = data['Weight'].values\n",
    "\n",
    "# Define the negative log-likelihood function\n",
    "def negative_log_likelihood(params, data):\n",
    "    mu, sigma = params[0], np.abs(params[1])  # Ensure sigma is positive\n",
    "    return -np.sum(norm.logpdf(data, loc=mu, scale=sigma))\n",
    "\n",
    "# Perform Maximum Likelihood Estimation (MLE) on the original dataset\n",
    "initial_guess = [np.mean(data), np.std(data)]\n",
    "mle_result = minimize(negative_log_likelihood, initial_guess, args=(data,))\n",
    "mle_params = mle_result.x\n",
    "print(f\"MLE estimates on original data: Mean = {mle_params[0]:.4f}, Std Dev = {mle_params[1]:.4f}\")\n",
    "\n",
    "# Bootstrapping process\n",
    "n_bootstraps = 1000\n",
    "boot_means = []\n",
    "boot_stds = []\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    # Sample with replacement\n",
    "    bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "    # Perform MLE on the bootstrap sample\n",
    "    result = minimize(negative_log_likelihood, initial_guess, args=(bootstrap_sample,))\n",
    "    params = result.x\n",
    "    boot_means.append(params[0])\n",
    "    boot_stds.append(np.abs(params[1]))\n",
    "\n",
    "# Compute statistics from bootstrapped MLEs\n",
    "mean_estimate = np.mean(boot_means)\n",
    "std_dev_estimate = np.mean(boot_stds)\n",
    "mean_conf_interval = np.percentile(boot_means, [2.5, 97.5])\n",
    "std_conf_interval = np.percentile(boot_stds, [2.5, 97.5])\n",
    "\n",
    "print(f\"Bootstrap Mean Estimate = {mean_estimate:.4f}\")\n",
    "print(f\"Bootstrap Std Dev Estimate = {std_dev_estimate:.4f}\")\n",
    "print(f\"95% Confidence Interval for Mean = {mean_conf_interval}\")\n",
    "print(f\"95% Confidence Interval for Std Dev = {std_conf_interval}\")\n",
    "\n",
    "# Plot the bootstrap distributions\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(boot_means, bins=30, color='blue', alpha=0.7)\n",
    "plt.axvline(mean_estimate, color='red', linestyle='dashed', linewidth=2)\n",
    "plt.title(\"Bootstrapped Means\")\n",
    "plt.xlabel(\"Mean\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(boot_stds, bins=30, color='green', alpha=0.7)\n",
    "plt.axvline(std_dev_estimate, color='red', linestyle='dashed', linewidth=2)\n",
    "plt.title(\"Bootstrapped Std Deviations\")\n",
    "plt.xlabel(\"Std Dev\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scenario: Drug effect outcomes, 1 for positive effect, 0 for negative effect\n",
    "data = np.array([1]*5 + [0]*3)  # 5 positive outcomes, 3 negative outcomes\n",
    "\n",
    "# MLE for binomial distribution (estimating probability of success)\n",
    "def negative_log_likelihood(p, data):\n",
    "    likelihood = np.sum(data * np.log(p) + (1 - data) * np.log(1 - p))\n",
    "    return -likelihood  # negative because we minimize the NLL\n",
    "\n",
    "# Find the MLE (probability of success)\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Initial guess for probability p\n",
    "initial_p = 0.5\n",
    "\n",
    "# Optimize to find the MLE estimate for p\n",
    "result = minimize(negative_log_likelihood, initial_p, args=(data,), bounds=[(0, 1)])\n",
    "p_mle = result.x[0]\n",
    "\n",
    "print(f\"MLE estimate of probability (p): {p_mle:.4f}\")\n",
    "\n",
    "# Bootstrap resampling to estimate confidence intervals\n",
    "n_iterations = 1000\n",
    "bootstrap_estimates = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "    result = minimize(negative_log_likelihood, initial_p, args=(bootstrap_sample,), bounds=[(0, 1)])\n",
    "    bootstrap_estimates.append(result.x[0])\n",
    "\n",
    "bootstrap_estimates = np.array(bootstrap_estimates)\n",
    "confidence_interval = np.percentile(bootstrap_estimates, [2.5, 97.5])\n",
    "\n",
    "print(f\"95% Confidence Interval for probability: {confidence_interval}\")\n",
    "\n",
    "# Plot the distribution of bootstrap estimates\n",
    "plt.hist(bootstrap_estimates, bins=30, edgecolor='k')\n",
    "plt.axvline(p_mle, color='red', label=f'MLE Estimate (p): {p_mle:.4f}')\n",
    "plt.axvline(confidence_interval[0], color='green', linestyle='--', label=f'2.5% CI: {confidence_interval[0]:.4f}')\n",
    "plt.axvline(confidence_interval[1], color='green', linestyle='--', label=f'97.5% CI: {confidence_interval[1]:.4f}')\n",
    "plt.title('Bootstrap Distribution of MLE Estimates')\n",
    "plt.xlabel('Probability of Success (p)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Define the dataset\n",
    "data = np.array([1]*5 + [0]*3)  # 1 for success (5 people), 0 for failure (3 people)\n",
    "\n",
    "# Step 2: Define the negative log-likelihood function for the binomial distribution\n",
    "def negative_log_likelihood(p, data):\n",
    "    likelihoods = data * np.log(p) + (1 - data) * np.log(1 - p)\n",
    "    return -np.sum(likelihoods)\n",
    "\n",
    "# Step 3: Bootstrap resampling\n",
    "def bootstrap_resample(data, n_iterations=1000):\n",
    "    n = len(data)\n",
    "    estimates = []\n",
    "    for i in range(n_iterations):\n",
    "        sample = np.random.choice(data, size=n, replace=True)\n",
    "        # Step 4: Minimize negative log-likelihood for each bootstrap sample\n",
    "        result = minimize(negative_log_likelihood, x0=0.5, args=(sample,), bounds=[(0, 1)])\n",
    "        estimates.append(result.x[0])  # Store the estimate of p (success probability)\n",
    "    return estimates\n",
    "\n",
    "# Step 5: Perform bootstrap MLE and calculate the confidence interval\n",
    "bootstrap_estimates = bootstrap_resample(data)\n",
    "mean_estimate = np.mean(bootstrap_estimates)\n",
    "confidence_interval = np.percentile(bootstrap_estimates, [2.5, 97.5])\n",
    "\n",
    "# Output results\n",
    "print(f\"Mean Estimate of Success Probability: {mean_estimate:.3f}\")\n",
    "print(f\"95% Confidence Interval for Success Probability: {confidence_interval}\")\n",
    "\n",
    "# Visualize the bootstrap distribution of estimates\n",
    "plt.hist(bootstrap_estimates, bins=30, edgecolor='black')\n",
    "plt.title('Bootstrap Distribution of Success Probability Estimates')\n",
    "plt.xlabel('Success Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
